# Запуск
Пример аргументов.
test.txt 3123 odd&&positive::distinct::asc positive::desc

Самым первым идёт название, куда генерируются числа (в данном примере test.txt).
Далее количество чисел (в данном примере 3123).

Далее идёт пример выбора чисел доступны следующие варианты:
odd, even, positive, negative.

Данные выборки можно комбинировать с помощью &&, то есть odd&&positive - нечётный и > 0;

Далее через :: идёт сортировка и удаление повторов:
distinct, asc (сортировка по возрастанию), desc (сортировка по убыванию).

Потом через пробел можно добавлять новые способы выборки, они будут обработаны в отдельном потоке и добавлены в разные файлы.

Отстутсвие названия test.txt - никак не обработано ( в итоге будет ошибка ).
Отсутствие количества - никак не обработно (в итоге будет ошибка ).

Также мы можем просто отсортировать элементы или убрать одинаковые или всё сразу,
написав так !::result.txt::distinct::asc

или можем сделать вот так even&&positive::result.txt

Общий вид такой (название файла куда генерируется) (количество) (параметрывыборки&&...::название файла с результатом::убрать повторы::сортировка)......(параметрывыборки&&...::название файла с результатом::убрать повторы::сортировка)

Восклицательный знак мы можем использвать в параметрах выборки, для того, чтобы исключить действие. even::result.txt:: (не работает на название файла с результатом)

# Общее
Я забыл спросить про ограничение по памяти. Если у нас нет данного ограничения, то 
удаление повторяющихся элементов можно добиться с помощью LinkedHashSet, просто добавляя элементы в множество.
Отсортировать элементы точно также можно с помощью stream + sorted. 

Однако если это ограничение есть, то задача становится намного сложнее, так как если мы попробуем уместить большое количество чисел в массив, то будет MemoryHeapError.
Я сделал MemoryPipe, который по достижению капа памяти (у меня он захардкоден как 0xFFFFFF) выгружает из RAM на HDD.
Соответственно у нас образуется из одного файла [.....] -> { [...], [...], [...] } множество подфайлов с числами.

Я придумал следующее. Я создал StreamPipe, который объединяет все файлы в один "поток". 
Далее всё зависит от условия. Если у нас выбрана сортировка, то во время образования множества подфайлов, каждый из них сортируется.
И потом выбирается нужный нам элемент из StreamPipe.

К сожалению я не придумал способ, который при вызове DISTINCT(убрать повторяющиеся) не будет сортировать. То есть при вызове DISTINCT 
он удалит повторяющиеся элементы, но он всё равно отсортирует, так как алгоритм следующий.
[.....] -> { [...], [...], [...] } - во время разбития, каждый из подфайлов будет отсортирован. 
Далее по компоратору выбирается (минимальный или максимальный, 
в зависимости от сортировки) элемент и сравниваем его с предыдущим положенным элементом в исходный файл => если равны, не добавляем в результат.

# Тест
Алгоритм не эффективный 117.071 секунд для 100_000_000 элементов со следующими аргументами test.txt 100000000 even::res.txt::distinct::desc
(Тест был на процессоре Intel core i5 u5200 2.2ghz и  RAM ddrl3 1600mhz 4GB).

# Мини док
Класс SimpleSequenceGenerator генерирует последовательность.
Далее парсятся аргументы и на их основе создаются SegregationThread, которые отвечают за разбитие элементов.

В SegregationThread идет процесс разбития элементов.





